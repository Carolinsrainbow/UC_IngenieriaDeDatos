{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carolinsrainbow/UC_IngenieriaDeDatos/blob/main/Final_CarolinaHerreraAzolas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabajo final -- formulario de carga de datos y respuestas\n",
        "\n",
        "En este notebook pueden ingresar sus respuestas a las preguntas del trabajo final y asegurarse que sus comandos SQL funcionan de manera adecuada.\n",
        "\n",
        "**IMPORTANTE**: **Debes entregar tu notebook ejecutado según tus últimos cambios ya que se revisarán los resultados en base a lo que salga ejecutado del notebook.**\n",
        "\n",
        "En el menú superior de google colab > Entorno de ejecución > Ejecutar todo,  tienes la opción de ejecutar todas las celdas del notebook. Puedes realizar esta acción antes de entregar tu tarea para asegurarte de que tus últimos cambios en el código sean los ejecutados.\n"
      ],
      "metadata": {
        "id": "8BXXue8KDsQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Cargar SQLite y subir la base de datos a Google Colab\n",
        "\n",
        "Cómo siempre, para poder ocupar el notebook, lo deben subir a https://colab.research.google.com\n",
        "\n",
        "Luego, ejecutando el siguiente campo, se crea una instancia de servidor SQLite, se creará el esquema vista en el enunciado, y se cargarán los datos desde un google drive."
      ],
      "metadata": {
        "id": "-GIMqhcTEPx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install\n",
        "!apt update\n",
        "!apt install postgresql postgresql-contrib &>log\n",
        "!service postgresql start\n",
        "!sudo -u postgres psql -c \"CREATE USER root WITH SUPERUSER\"\n",
        "# pin package versions for google colab compatibility\n",
        "!pip install SQLAlchemy==1.4.46\n",
        "!pip install ipython-sql==0.4.1\n",
        "%load_ext sql\n",
        "\n",
        "# Cargamos SQL y la base de datos:\n",
        "!wget -O datos_T3.db --no-check-certificate https://drive.google.com/uc\\?export\\=download\\&id\\=14puII6h6V45QY_FwRsgY_g86y7hf9IcE\n",
        "\n",
        "%sql sqlite:///datos_T3.db\n",
        "\n",
        "# Descargamos los csv:\n",
        "!wget -O Ciudad.csv --no-check-certificate https://drive.google.com/uc\\?export\\=download\\&id\\=1jlpOj22VLlhRzsLwyyylR8MuHILrxdiT\n",
        "!wget -O Pais.csv --no-check-certificate https://drive.google.com/uc\\?export\\=download\\&id\\=1dQNdoeKbk60SMH6x04zW09zOF-kOsZ0P\n",
        "!wget -O CiudadPais.csv --no-check-certificate https://drive.google.com/uc\\?export\\=download\\&id\\=1bOpRAsKJmWkX9T5LdGnz3h1nxHBiJCok\n",
        "\n",
        "# Importamos Pandas:\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "OVSDhz3-hrku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02b1497-dad6-4a45-d1a4-3d887e45a18c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ubuntu.com (91.189.91.8\u001b[0m\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcontent.net (185.125.190.\u001b[0m\r                                                                                                    \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r                                                                                                    \rHit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "48 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            " * Starting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "ERROR:  role \"root\" already exists\n",
            "Requirement already satisfied: SQLAlchemy==1.4.46 in /usr/local/lib/python3.10/dist-packages (1.4.46)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy==1.4.46) (3.0.3)\n",
            "Requirement already satisfied: ipython-sql==0.4.1 in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: prettytable<1 in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (0.7.2)\n",
            "Requirement already satisfied: ipython>=1.0 in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (7.34.0)\n",
            "Requirement already satisfied: sqlalchemy>=0.6.7 in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (1.4.46)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=0.6.7->ipython-sql==0.4.1) (3.0.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=1.0->ipython-sql==0.4.1) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=1.0->ipython-sql==0.4.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql==0.4.1) (0.2.13)\n",
            "The sql extension is already loaded. To reload it, use:\n",
            "  %reload_ext sql\n",
            "--2024-05-09 13:05:25--  https://drive.google.com/uc?export=download&id=14puII6h6V45QY_FwRsgY_g86y7hf9IcE\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.197.113, 74.125.197.138, 74.125.197.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.197.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=14puII6h6V45QY_FwRsgY_g86y7hf9IcE&export=download [following]\n",
            "--2024-05-09 13:05:25--  https://drive.usercontent.google.com/download?id=14puII6h6V45QY_FwRsgY_g86y7hf9IcE&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.197.132, 2607:f8b0:400e:c03::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.197.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 126976 (124K) [application/octet-stream]\n",
            "Saving to: ‘datos_T3.db’\n",
            "\n",
            "datos_T3.db         100%[===================>] 124.00K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-05-09 13:05:26 (89.2 MB/s) - ‘datos_T3.db’ saved [126976/126976]\n",
            "\n",
            "--2024-05-09 13:05:26--  https://drive.google.com/uc?export=download&id=1jlpOj22VLlhRzsLwyyylR8MuHILrxdiT\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.197.113, 74.125.197.138, 74.125.197.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.197.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1jlpOj22VLlhRzsLwyyylR8MuHILrxdiT&export=download [following]\n",
            "--2024-05-09 13:05:26--  https://drive.usercontent.google.com/download?id=1jlpOj22VLlhRzsLwyyylR8MuHILrxdiT&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.197.132, 2607:f8b0:400e:c03::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.197.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1309 (1.3K) [application/octet-stream]\n",
            "Saving to: ‘Ciudad.csv’\n",
            "\n",
            "Ciudad.csv          100%[===================>]   1.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-09 13:05:26 (99.2 MB/s) - ‘Ciudad.csv’ saved [1309/1309]\n",
            "\n",
            "--2024-05-09 13:05:26--  https://drive.google.com/uc?export=download&id=1dQNdoeKbk60SMH6x04zW09zOF-kOsZ0P\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.197.113, 74.125.197.138, 74.125.197.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.197.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1dQNdoeKbk60SMH6x04zW09zOF-kOsZ0P&export=download [following]\n",
            "--2024-05-09 13:05:27--  https://drive.usercontent.google.com/download?id=1dQNdoeKbk60SMH6x04zW09zOF-kOsZ0P&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.197.132, 2607:f8b0:400e:c03::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.197.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 936 [application/octet-stream]\n",
            "Saving to: ‘Pais.csv’\n",
            "\n",
            "Pais.csv            100%[===================>]     936  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-09 13:05:31 (35.7 MB/s) - ‘Pais.csv’ saved [936/936]\n",
            "\n",
            "--2024-05-09 13:05:31--  https://drive.google.com/uc?export=download&id=1bOpRAsKJmWkX9T5LdGnz3h1nxHBiJCok\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.197.113, 74.125.197.138, 74.125.197.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.197.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1bOpRAsKJmWkX9T5LdGnz3h1nxHBiJCok&export=download [following]\n",
            "--2024-05-09 13:05:31--  https://drive.usercontent.google.com/download?id=1bOpRAsKJmWkX9T5LdGnz3h1nxHBiJCok&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.197.132, 2607:f8b0:400e:c03::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.197.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 474 [application/octet-stream]\n",
            "Saving to: ‘CiudadPais.csv’\n",
            "\n",
            "CiudadPais.csv      100%[===================>]     474  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-09 13:05:32 (16.3 MB/s) - ‘CiudadPais.csv’ saved [474/474]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pregunta 1\n",
        "\n",
        "En esta primera pregunta, te pedimos ejecutar la primera celda del  notebook para configurar el entorno de SQL, y descargar la base de datos de tareas 2/3  además de los tres archivos CSV.\n",
        "\n",
        "Luego, te pedimos crear las tablas nuevas con los atributos adecuados (los nombres deben coincidir con los nombres de la especificación de arriba, y los tipos de atributos los debes asignar tú). Para guiar un poco tu diseño de distintos tipos de atributos, te dejamos dos ejemplos con tipos de datos especificados:\n",
        "\n",
        "```\n",
        "Persona(rut VARCHAR(100) PRIMARY KEY, nombre VARCHAR(100), correo VARCHAR(100), telefono VARCHAR(100));\n",
        "\n",
        "Paises(pid INT PRIMARY KEY, nombre VARCHAR(100));\n",
        "```\n",
        "\n",
        "Para esto, debes escribir un comando del tipo `CREATE TABLE…` en SQL para cada tabla marcada con *** en la especificación de arriba. El punto del ejercicio es modificar tu base de datos tal que al final de la tarea contenga los datos necesarios. Quiere decir que, algunas tablas se mantienen como están (por ejemplo Persona) y algunas se pueden borrar al final del ejercicio.\n",
        "\n",
        "**Importante**: No te olvides de especificar las llaves primarias y foráneas. Por ejemplo, tenemos que IDCiudad es una llave foránea en la tabla LugarNuevo (para Ciudades), o que rut es la llave foránea en Participa.\n",
        "\n"
      ],
      "metadata": {
        "id": "Pwj39cMXFB9b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ZECs_9rhjNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "70P9iLamtiuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Q3k5Kp-ti1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pregunta 2\n",
        "\n",
        "Inserta a las tablas `Taller`, `Deportivo` e `Instumental` los datos que se piden según su esquema, desde las tablas `TallerDeportivo` y `TallerInstrumental` que ya existen en tu base de datos.\n",
        "\n",
        "Para esto puedes ocupar SQL, Pandas, Python, lo que sea. Una buena alternativa se propone en el siguiente link: https://www.w3schools.com/sql/sql_insert_into_select.asp\n",
        "\n",
        "También pueden ver el siguiente link: https://stackoverflow.com/questions/71362727/python-sqlite3-insert-data-from-for-loop (si siguen esta forma, recuerden hacer commit a la connection luego de ejecutar el INSERT INTO )"
      ],
      "metadata": {
        "id": "yB4d1b1KFw3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NcLY99I3F32R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WZnPL48lto3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zZb_I2B4tryF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, ejecuta las siguientes celdas para corroborar que los datos se hayan cargado de forma correcta:"
      ],
      "metadata": {
        "id": "1BE14L8ltbi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM Taller LIMIT"
      ],
      "metadata": {
        "id": "nPyMJFKVtVXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM Deportivo LIMIT 10"
      ],
      "metadata": {
        "id": "lasuwtA9tXsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM Instrumental LIMIT 10"
      ],
      "metadata": {
        "id": "TvVr3LvitYKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pregunta 3\n",
        "\n",
        "Ocupando los 3 csv entregados, llena las tablas `País` y `Ciudad` del esquema nuevo. Para esto, hay que hacer un join entre los csv. De nuevo, esto lo puedes hacer con Pandas (cargando los tres CSV a SQL)  o con Python.\n",
        "\n",
        "Aquí puedes cargar los csvs en Pandas, y luego ocupar este tutorial para cargar datos desde un dataframe a una tabla SQL: https://datacarpentry.org/python-ecology-lesson/09-working-with-sql/index.html\n",
        "\n",
        "Alternativamente, lo más fácil sería cargar datos desde un csv directamente a sqlite, como se explica aquí: https://www.sqlitetutorial.net/sqlite-import-csv/\n",
        " (pero para esto, debes tener sqlite3 instalado en tu computador)\n",
        "\n",
        "Otro link que puede ser de utilidad es el siguiente: https://kontext.tech/article/633/pandas-save-dataframe-to-sqlite"
      ],
      "metadata": {
        "id": "5ajnI5m7F9pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dz23KWdDGU-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "COsFE6eutvlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VhGQvnTGt1k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, ejecuta las siguientes celdas para corroborar que los datos se hayan cargado de forma correcta:"
      ],
      "metadata": {
        "id": "5DK56yuQt19D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM Pais limit 5"
      ],
      "metadata": {
        "id": "zmZ1qtNRtvwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM Ciudad limit 5"
      ],
      "metadata": {
        "id": "-l8_1U0ctyhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pregunta 4\n",
        "\n",
        "Llena la tabla LugarNuevo de tu esquema con los datos que se piden. Para esto necesitas ocupar la tabla Lugar (que viene en la base de datos anterior)  y las tablas Ciudad y País (o los CSVs si prefieres).\n",
        "\n",
        "Debes tener cuidado al cruzar la información de las ciudades proveniente de la base de datos anterior con las ciudades que vienen de los archivos nuevos, ya que no todas las ciudades tendrán lugares asociados en la base de datos anterior. La idea es que no queden nulos en tu base de datos.\n",
        "\n",
        "\n",
        "Quizás te puede servir este link https://datatofish.com/sql-to-pandas-dataframe/"
      ],
      "metadata": {
        "id": "7OyQmth3GgJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lQOBVFpoGn0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "40ASUO1Lt8bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q6SAEciZt8k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, ejecuta la siguiente celda para corroborar que los datos se hayan cargado de forma correcta:"
      ],
      "metadata": {
        "id": "aaYqxxbNt_9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM LugarNuevo limit 5"
      ],
      "metadata": {
        "id": "jaczJHa6t9dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pregunta 5\n",
        "\n",
        "Ahora que terminamos la carga de datos en las tablas nuevas, es tiempo de limpiar nuestra base de datos. Para esto te pedimos borrar las tablas: `Lugar`, `TallerInstrumental` y `TallerDeportivo` de la base de datos antigua."
      ],
      "metadata": {
        "id": "VqoJcVwnjJHu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rLhDXnkYku0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fcM0Qrx3uGKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1HKHMv-RuGRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, ejecuta las siguientes celdas para corroborar que las tablas se hayan eliminado de forma correcta. Si es que una tabla se borró correctamente, la ejecución de la consulta te debería devolver el siguiente error:\n",
        "```\n",
        "* sqlite:///datos_T3.db\n",
        "(sqlite3.OperationalError) no such table: NombreTabla):\n",
        "```"
      ],
      "metadata": {
        "id": "duN7vzUVuKot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM Lugar"
      ],
      "metadata": {
        "id": "hte2XArnuGu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM TallerDeportivo"
      ],
      "metadata": {
        "id": "LOs5GbNJuHWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT * FROM TallerInstrumental"
      ],
      "metadata": {
        "id": "Ptj31rkNuHYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 6\n",
        "\n",
        "Con nuestra base de datos lista, podemos hacer un poco de análisis de los datos. En esta pregunta, te pedimos escribir una consulta SQL que ordene los talleres deportivos según la participación. Quiere decir, debes devolver **id del taller, nombre del taller, nombre del deporte y la cantidad de gente distinta que participa en este taller**, ordenado de forma descendente."
      ],
      "metadata": {
        "id": "bHLUX6EDJKzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql"
      ],
      "metadata": {
        "id": "8VFsYhe4JK_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "3fbf7b10-c7fe-476e-c77c-597e04102f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: %%sql is a cell magic, but the cell body is empty. Did you mean the line magic %sql (single %)?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 7\n",
        "\n",
        "En esta pregunta debes escribir una consulta SQL que entregue el **nombre y país de la ciudad** donde se organiza la máxima cantidad de talleres instrumentales. Quiere decir, hay que calcular cuántos talleres instrumentales hay en cada ciudad, y devolver la(s) ciudad(es) dónde se alcanza el número máximo.\n"
      ],
      "metadata": {
        "id": "RtdDR4ICJLIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql"
      ],
      "metadata": {
        "id": "VQULBgRhJLQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 8\n",
        "\n",
        "En esta pregunta queremos saber los nombres de los países con la cantidad máxima de lugares con al menos 2 talleres deportivos (2 o más) organizados en estos lugares. Quiere decir, para cada lugar hay que ver si hay al menos 2 talleres deportivos en él, y se necesita devolver **el país con la cantidad maxima de lugares** con esta propiedad."
      ],
      "metadata": {
        "id": "qXujz0_-KIRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql"
      ],
      "metadata": {
        "id": "THPoqjevjMr7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}